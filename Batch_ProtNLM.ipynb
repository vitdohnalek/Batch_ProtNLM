{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCuI3G1qcZJ8"
      },
      "source": [
        "```\n",
        "# Copyright 2025 Vít Dohnálek.\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSfRFuO5tive",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Prepare Tensorflow\n",
        "\n",
        "!python3 -m pip install -q -U tensorflow==2.8.2\n",
        "!python3 -m pip install -q -U tensorflow-text==2.8.2\n",
        "import tensorflow as tf\n",
        "import tensorflow_text\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import IPython.display\n",
        "from absl import logging\n",
        "\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "logging.set_verbosity(logging.ERROR)  # Turn down tensorflow warnings\n",
        "\n",
        "def print_markdown(string):\n",
        "  IPython.display.display(IPython.display.Markdown(string))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIZGEiYMXqUD",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Prepare Functions\n",
        "\n",
        "def query(seq):\n",
        "  return f\"[protein_name_in_english] <extra_id_0> [sequence] {seq}\"\n",
        "\n",
        "EC_NUMBER_REGEX = r'(\\d+).([\\d\\-n]+).([\\d\\-n]+).([\\d\\-n]+)'\n",
        "\n",
        "def run_inference(seq):\n",
        "  labeling = infer(tf.constant([query(seq)]))\n",
        "  names = labeling['output_0'][0].numpy().tolist()\n",
        "  scores = labeling['output_1'][0].numpy().tolist()\n",
        "  beam_size = len(names)\n",
        "  names = [names[beam_size-1-i].decode().replace('<extra_id_0> ', '') for i in range(beam_size)]\n",
        "  for i, name in enumerate(names):\n",
        "    if re.match(EC_NUMBER_REGEX, name):\n",
        "      names[i] = 'EC:' + name\n",
        "  scores = [np.exp(scores[beam_size-1-i]) for i in range(beam_size)]\n",
        "  return names, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9YtieGL6YRk",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load Model\n",
        "\n",
        "!pip install biopython\n",
        "! mkdir -p protnlm\n",
        "\n",
        "! wget -nc https://storage.googleapis.com/brain-genomics-public/research/proteins/protnlm/uniprot_2022_04/savedmodel__20221011__030822_1128_bs1.bm10.eos_cpu/saved_model.pb -P protnlm -q --no-check-certificate\n",
        "! mkdir -p protnlm/variables\n",
        "! wget -nc https://storage.googleapis.com/brain-genomics-public/research/proteins/protnlm/uniprot_2022_04/savedmodel__20221011__030822_1128_bs1.bm10.eos_cpu/variables/variables.index -P protnlm/variables/ -q --no-check-certificate\n",
        "! wget -nc https://storage.googleapis.com/brain-genomics-public/research/proteins/protnlm/uniprot_2022_04/savedmodel__20221011__030822_1128_bs1.bm10.eos_cpu/variables/variables.data-00000-of-00001 -P protnlm/variables/ -q --no-check-certificate\n",
        "\n",
        "imported = tf.saved_model.load(export_dir=\"protnlm\")\n",
        "infer = imported.signatures[\"serving_default\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "import glob\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "output_path = \"/content/gdrive/My Drive/ProtNLM_RESULTS.tsv\" #@param {type:\"string\"}\n",
        "#@markdown - Output path & name; results will be written into a .tsv file\n",
        "#@markdown - Appends results after each prediction\n",
        "\n",
        "files = []\n",
        "for file in glob.glob(f\"/{input_folder.strip('/')}/*.pdb\"):\n",
        "  files.append(file)\n",
        "\n",
        "print(f\"Collected {len(files)} pdb files\")"
      ],
      "metadata": {
        "id": "dKrSp1ap6nYp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload fasta file\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename from the uploaded dictionary\n",
        "fasta_file = list(uploaded.keys())[0]"
      ],
      "metadata": {
        "id": "nlDjyr959T5S",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUDDawYq4e3B",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 3. ProtNLM Predictions\n",
        "from Bio import SeqIO\n",
        "import os\n",
        "\n",
        "\n",
        "table_rows = [[\"Protein ID\",\"Hit 1\",\"Hit 1 Score\",\"Hit 2\",\"Hit 2 Score\",\"Hit 3\",\"Hit 3 Score\",\"Hit 4\",\"Hit 4 Score\",\"Hit 5\",\"Hit 5 Score\"]]\n",
        "\n",
        "#Sets up the result files and writes the header\n",
        "with open(f\"/{output_path.strip('/')}\", \"w\") as f:\n",
        "  f.write(\"\\t\".join(table_rows[0]) + \"\\n\")\n",
        "\n",
        "for seq_rec in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "\n",
        "  sequence_ID = seq_rec.id\n",
        "  sequence = str(seq_rec.seq)\n",
        "  sequence = sequence.replace(' ', '')\n",
        "\n",
        "  names, scores = run_inference(sequence)\n",
        "  results = [sequence_ID]\n",
        "\n",
        "  for name, score, i in zip(names, scores, range(len(names))):\n",
        "    if i+1 <= 5:\n",
        "      #print_markdown(f\"Prediction number {i+1}: **{name}** with a score of **{score:.03f}**\")\n",
        "      score = f\"{score:.03f}\"\n",
        "      results.append(name)\n",
        "      results.append(score)\n",
        "\n",
        "  with open(f\"/{output_path.strip('/')}\", \"a\") as f:\n",
        "    f.write(\"\\t\".join(results) + \"\\n\")\n",
        "\n",
        "  print(f\"ProtNLM prediction for {sequence_ID} has been done... \")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
